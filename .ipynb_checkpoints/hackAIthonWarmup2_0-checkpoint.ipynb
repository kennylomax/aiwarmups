{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f5041f7-0bf9-4c8b-9176-e6d5bf53f132",
   "metadata": {},
   "source": [
    "<h1>Training and Using ML Models in minutes, without a Maths PhD</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f07ad-f507-4250-8fe5-00f26dbaadf5",
   "metadata": {},
   "source": [
    "# Intro to this journey..\n",
    "\n",
    "This journey takes ideas from the excellent videos at [Practical Deep Learning for Coders](https://course.fast.ai/)..\n",
    "\n",
    "In this journey, we will be using:\n",
    "- [Jupyter Labs](https://jupyter.org/) (A next-generation notebook/tutorial interface) to \n",
    "- [Hugging Face](https://huggingface.co/docs/hub/index) (The Hugging Face Hub is a platform with over 600k models, 75k datasets, and 150k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together.)\n",
    "- [Gradio](https://www.gradio.app/) (Gradio is the fastest way to demo your machine learning model with a friendly web interface so that anyone can use it, anywhere!)\n",
    "- [DuckDuckGo](https://duckduckgo.com/) (A search engine with simple API)\n",
    "\n",
    "# .. to see how easy it is to adapt ML Models to your business requirement.  \n",
    "\n",
    "We will:\n",
    "\n",
    "- try some ML models, requiring 2 lines of python code to call each one..\n",
    "- find a model that is close to what we need but needs extra training\n",
    "- \"further train\" or \"fine-tune\" it, to create our own model \n",
    "- use our new model in a variety of ways\n",
    "  - via python API, via CURL, via a website\n",
    "\n",
    "# Prerequisites to follow this journey yourself:\n",
    "\n",
    "- install python: https://www.python.org  \n",
    "- install and launch Jupyter Labs: https://jupyter.org/install\n",
    "- create an account on Hugging Face: https://huggingface.co/docs/hub/index\n",
    "- install Git: https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\n",
    "- git clone https://github.com/kennylomax/aiwarmups.git\n",
    "- cd aiwarmups\n",
    "- pip install nbclassic\n",
    "- jupyter nbclassic hackAIthonWarmup2_0.ipynb\n",
    "\n",
    "# A Top Tip from an ML Newbie to get started ..\n",
    "\n",
    "- Watch the video at the top of https://course.fast.ai/Lessons/lesson1.html\n",
    "- Watch the intro to Generative AI https://open.sap.com/courses/genai1\n",
    "- Play around in Jupyter Labs\n",
    "- Get comfortable with basic Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462807b-071f-4216-a780-4d46ff58c447",
   "metadata": {},
   "source": [
    "## Introducing Hugging Face ...\n",
    "\n",
    "[Hugging Face](https://huggingface.co/docs/hub/index) is \"a platform with over 600k models, 75k datasets, and 150k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together. \" [more..](https://huggingface.co/docs/hub/index)\n",
    "\n",
    "Let's try using some of the models, and pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6958c-d3db-437d-b021-732a913aee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code blocks like this allow us to write and execute Python Code RIGHT HERE in this page\n",
    "# In this first python block we import some useful libraries, which we will be using in code blocks further down\n",
    "print (\"Starting to import\")\n",
    "from itertools import islice\n",
    "from duckduckgo_search import DDGS\n",
    "from fastcore.all import *\n",
    "from fastdownload import download_url\n",
    "from fastai.vision.all import *\n",
    "from time import sleep\n",
    "import IPython\n",
    "from transformers import pipeline\n",
    "print (\"Finished importing..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eeab8c-3086-4811-a427-7c4cefbd55bc",
   "metadata": {},
   "source": [
    "### How about a model for text sentiment analysis?\n",
    "\n",
    "https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14f061-730f-4571-8513-d8ee885edd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "#print (pipe(\"Sometimes I feel overwhelmed by ML, and not sure where to start..\") )\n",
    "print (pipe(\"But it seems I can use ML Models with 1 line of Python. This is pretty amazing! \") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c994d32-b9de-4e66-8f4d-0f76c032716a",
   "metadata": {},
   "source": [
    "### How about a model for speech recognition?\n",
    "https://huggingface.co/openai/whisper-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc895c4-07e3-495b-86cb-c3ce6c416b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(model=\"openai/whisper-base\")\n",
    "pipe(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2867f36-cb70-4601-9aa8-9760eb697148",
   "metadata": {},
   "source": [
    "### How about about a model for object detection\n",
    "https://huggingface.co/facebook/detr-resnet-50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332c19d-8449-4e22-928d-3102dc94bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://3.bp.blogspot.com/-EhDfNXRF328/T-tc5MY-KnI/AAAAAAAAAAw/KVptY3L3eG0/s1600/shutterstock_95676709_twokittens.jpg\"\n",
    "IPython.display.Image(url, width = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667fae1-1573-46ad-9cc8-9b43b7f39b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(model=\"facebook/detr-resnet-50\")\n",
    "pipe(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2385108e-ad27-4c1e-8934-87e177abb1fc",
   "metadata": {},
   "source": [
    "## Note on image retrievals..\n",
    "\n",
    "You can run into access problems if trying to reference URLs directly from the internet\n",
    "It will help us to have a function that returns urls of downloadable images from DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e4c8d-2f5b-4c48-8eeb-c98059c2cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagesUsingDuckduckgo(searchTerm, max_images=50):\n",
    "    print( \"Searching for \", {searchTerm} )\n",
    "    return L(islice( DDGS().images(searchTerm), max_images) ).itemgot('image') # L is a drop in replacement for a python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02109abc-e539-42e9-ad77-911b1b646696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download a picture of kittens using DuckDuckGo\n",
    "urls = getImagesUsingDuckduckgo('2 puppies', 1 )\n",
    "download_url( urls[0], 'scratch/2puppies.jpg')\n",
    "im1 = Image.open('scratch/2puppies.jpg')\n",
    "im1.to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28bdd86-5b95-4558-b69c-e4454aac4c20",
   "metadata": {},
   "source": [
    "### How about a model for image captioning\n",
    "https://huggingface.co/nlpconnect/vit-gpt2-image-captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18618959-a6ca-429f-9f5d-6de75d2db8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "pipe(im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f2ec82-9ddd-4acc-9c88-5fda47e15747",
   "metadata": {},
   "source": [
    "### How about some classic image recognition\n",
    "https://huggingface.co/microsoft/resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54044b62-0e76-4cc1-bb86-79ba83ae4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = getImagesUsingDuckduckgo('a duck photo',1 )\n",
    "print(\"URL returned from getImagesUsingDuckduckgo with 'duck photo' is: \"+urls[0])\n",
    "download_url( urls[0], 'scratch/duck.jpg')\n",
    "im1 = Image.open('scratch/duck.jpg')\n",
    "im1.to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a8d41-c04e-407d-acd4-2735290c2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"image-classification\", model=\"microsoft/resnet-18\")\n",
    "pipe(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1ee2a-0032-4a8c-8f57-85159943531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about recognising a zx80..\n",
    "urls = getImagesUsingDuckduckgo('zx80', 1 )\n",
    "download_url( urls[0], 'scratch/zx80.jpg')\n",
    "im1 = Image.open('scratch/zx80.jpg')\n",
    "im1.to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ac4a7-d3bf-4118-8306-4d91008c91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### How about image captioning\n",
    "pipe = pipeline(\"image-classification\", model=\"microsoft/resnet-18\")\n",
    "print ( pipe(im1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8358386-6cf7-4f48-877b-86e6e7d59391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about recognising a zx81..\n",
    "urls = getImagesUsingDuckduckgo('zx81', 1 )\n",
    "download_url( urls[0], 'scratch/zx81.jpg')\n",
    "im1 = Image.open('scratch/zx81.jpg')\n",
    "im1.to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcad9d5-b0df-4d2c-932d-d32cba02193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"image-classification\", model=\"microsoft/resnet-18\")\n",
    "print ( pipe(im1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c379646-9e96-4921-8bb7-a30e8062c874",
   "metadata": {},
   "source": [
    "# We will fine-tune the resnet-18 model to distinguish between zx80s and zx81s!\n",
    "\n",
    "We will be doing \"Supervised Learning\" using labelled data..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f906493-ecb7-40cf-9c08-24e56d024974",
   "metadata": {},
   "source": [
    "### Collect training data and sort it in a simple but clear way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20e8ca-0ef9-46d3-b558-b4bee14248d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a bunch of zx80 and zx81 images and place them in respective folders: scratch/imagespool/zx80 and scratch/imagespool/zx81:\n",
    "categories = 'zx80','zx81'\n",
    "path = Path('scratch/imagepool')\n",
    "for o in categories:\n",
    "    dest = (path/o)\n",
    "    dest.mkdir(exist_ok=True, parents=True)\n",
    "    download_images(dest, urls=getImagesUsingDuckduckgo(f'{o} photo'))\n",
    "    sleep(10)  # Pause between searches to avoid over-loading server\n",
    "    resize_images(path/o, max_size=400, dest=path/o)\n",
    "print (\"Finished loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f93c4b-127f-43b2-86ae-ba9c3fe19f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any images that failed to download properly:\n",
    "failed = verify_images(get_image_files(path))\n",
    "print (failed)\n",
    "failed.map(Path.unlink)\n",
    "print (\"Number of images removed: \", len(failed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c5a98b-4d03-44b5-b17d-967c1b7e262b",
   "metadata": {},
   "source": [
    "### Prepare the Training Data using a DataBlock\n",
    "The model expects a DataBlock to orchestrate feeding training data into the model..\n",
    "\n",
    "- TIP:\n",
    "  - Listen to few minutes on Datablock explanation by Jeremy Howard: https://youtu.be/8SF_h3xF3cE?si=UOZU-NAhEjSf8du_&t=2507\n",
    "  - See https://docs.fast.ai/tutorial.datablock.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6eb80-868e-4716-87b3-9156026aab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataBlock handles all common usecases for training MLs, including our use case: image categorisation\n",
    "# Getting the data into the right shape..\n",
    "dls = DataBlock(\n",
    "    blocks=(\n",
    "            # The sort of data are we using as input\n",
    "            ImageBlock, \n",
    "            # The sort of \"decision/output\" do we want the ML Model to make\n",
    "            CategoryBlock \n",
    "    ), \n",
    "    # A fast.io method for retrieving list of image files from dataloaders. path (See  https://docs.fast.ai/data.transforms.html#get_image_files )\n",
    "    get_items=get_image_files, \n",
    "    # Use 80% for training and 20% for validation ..\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42), \n",
    "    # Use the folder label in our case zx80 and zx81 for the label/category\n",
    "    get_y=parent_label, \n",
    "    # Run resize on every image in the data set: to set all images to be the same size\n",
    "    item_tfms=[Resize(192, method='squish')] \n",
    ").dataloaders( \n",
    "    # Feed the training algorithm with bunch(batch) or images at once\n",
    "    # The path where the input data is stored\n",
    "    path, \n",
    "    # The batch size these should be processed in \n",
    "    bs=32 \n",
    ")\n",
    "# Do a sanity check of the data that dls will be passing to the model for training\n",
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f592070-2e5d-444f-b999-075a2b434604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair our generic (pre-trained) model, and our Dataloader, inside a \"learner\" so we are ready to train it..\n",
    "learner = vision_learner(\n",
    "    # The dataloader from above\n",
    "    dls, \n",
    "    # The generic model that is good for image clarification. Also look into TIMM models..\n",
    "    resnet18, \n",
    "    metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b4fd3-de12-40e1-af07-104f4d13a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our learner knows it should categorise images between ZX80s and ZX81s...\n",
    "# Let's try it out before we train it..\n",
    "a,b,probs = learner.predict(PILImage.create('scratch/zx80.jpg'))\n",
    "print(f\"ZX80.. Prediction: {learner.dls.vocab} {a} {probs}\")\n",
    "a,b,probs = learner.predict(PILImage.create('scratch/zx81.jpg'))\n",
    "print(f\"ZX81.. Prediction: {learner.dls.vocab} {a} {probs}\")\n",
    "a,b,probs = learner.predict(PILImage.create('scratch/duck.jpg'))\n",
    "print(f\"Duck.. Prediction: {learner.dls.vocab} {a} {probs}\")\n",
    "\n",
    "# Note these are not good predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1ffa8-b849-4190-a778-bf9c939d8a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the fine tuning using our data with ONE LINE OF CODE!\n",
    "learner.fine_tune(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ad4b2-75fd-4a96-a075-9edd53832ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the model again and note the difference:\n",
    "a,b,probs = learner.predict(PILImage.create('scratch/zx80.jpg'))\n",
    "print(f\"ZX80.. Prediction: {learner.dls.vocab} {a} {probs}\")\n",
    "a,b,probs = learner.predict(PILImage.create('scratch/zx81.jpg'))\n",
    "print(f\"ZX81.. Prediction: {learner.dls.vocab} {a} {probs}\")\n",
    "a,b,probs = learner.predict(PILImage.create('scratch/duck.jpg'))\n",
    "print(f\"Duck.. Prediction: {learner.dls.vocab} {a} {probs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79fd089-fc69-4475-84e6-6df8be6d1121",
   "metadata": {},
   "source": [
    "# Sharing our amazing \"Is it a Zx80 or Zx81 Model\" with the world...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984032e4-772d-4d56-93f0-fc7d254babb4",
   "metadata": {},
   "source": [
    "### Export our trained model as a pickle file ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec167e9-6576-4ede-9a8f-2021d46c35b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.export()\n",
    "path = Path()\n",
    "path.ls(file_exts='.pkl')\n",
    "!mv export.pkl scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e5cbca-a37f-40e0-892d-ca2374d8dd67",
   "metadata": {},
   "source": [
    "### Using the pkl file directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e524c-7075-40a8-b5d4-a984b85a6307",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf = load_learner(path/'scratch/export.pkl')\n",
    "print ( learn_inf.predict('scratch/zx81.jpg'))\n",
    "print ( learn_inf.dls.vocab )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47808ee-dfd1-4084-8b0f-d710887cf3b4",
   "metadata": {},
   "source": [
    "### Push our model to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e709a-51bc-400b-bd8f-7bfd20880ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hugging token here: https://huggingface.co/settings/tokens\n",
    "# Then...\n",
    "!pip install huggingface_hub\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033df3f9-322f-4039-89d8-460c47af06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push model to hugging face\n",
    "from huggingface_hub import push_to_hub_fastai\n",
    "repo_id = \"kenlomax/zx80zx81b\"\n",
    "push_to_hub_fastai(learner=learner, repo_id=repo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734951b-8e64-465d-a613-f36a72185d4d",
   "metadata": {},
   "source": [
    "### Pull the model from Hugging Face and use it..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ca12e-8a95-4a7a-987c-f45709031663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anyone can now use this model ..\n",
    "!pip install toml\n",
    "from huggingface_hub import from_pretrained_fastai\n",
    "learner = from_pretrained_fastai(\"kenlomax/zx80zx81a\")\n",
    "\n",
    "_,_,probs = learner.predict(PILImage.create('scratch/zx81.jpg'))\n",
    "print(f\"Probability it's a zx80: {probs}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f3d96-27c9-4e06-a161-109d25ca0a1a",
   "metadata": {},
   "source": [
    "### Create a little website that uses our model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b0b92-1319-4397-af94-a2b7085530eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the dependencies\n",
    "requirementscode=\"\"\"\n",
    "gradio==3.48.0\n",
    "requests\n",
    "fastai\n",
    "\"\"\"\n",
    "f = open( 'scratch/requirements.txt', 'w' )\n",
    "f.write(requirementscode )\n",
    "f.close()\n",
    "\n",
    "!cat ./scratch/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54c87f-c444-4829-ae52-b29d60693cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the dependencies\n",
    "!pip install -r ./scratch/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be083bde-6bb1-4d05-b635-8d5df0a6b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "servercode=\"\"\"\n",
    "import gradio as gr\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# SeehackAIthonWarmup1_0.ipynb for discussion when to use Authorization\n",
    "# bearertoken = \"\" #os.environ['HACKAITHONBEARERTOKEN']  \n",
    "headers = {\"Authorization\": \"xxx\" }\n",
    "\n",
    "def query(filepath):\n",
    "    print (filepath);\n",
    "    data = open(filepath, 'rb' ).read()\n",
    "    from huggingface_hub import from_pretrained_fastai\n",
    "    learner = from_pretrained_fastai(\"kenlomax/zx80zx81a\") \n",
    "    _,_,probs = learner.predict(PILImage.create(data))\n",
    "    return ( learner.dls.vocab , \": \", probs)\n",
    "\n",
    "def useMyModel(image):\n",
    "    output = query( image)\n",
    "    print (str(output))\n",
    "    return str(output)\n",
    "\n",
    "iface = gr.Interface(\n",
    "  fn=useMyModel, inputs=[gr.Image(type=\"filepath\")], outputs=\"text\")\n",
    "iface.launch()\n",
    "\"\"\"\n",
    "f = open( 'scratch/app.py', 'w' )\n",
    "f.write(servercode )\n",
    "f.close()\n",
    "\n",
    "!ls -la ./scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94316cb8-cd06-443e-a085-a7a336427ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'scratch/app.py' \n",
    "# Wait a few seconds, and you should see the website's UI appear below.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba458e3-c803-4a5e-bfb6-f61a3aea4828",
   "metadata": {},
   "source": [
    "### Call our model via Hugging Face python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029405e-58d3-4405-81d9-3e7253d4da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!openssl base64 -in scratch/zx80.jpg | tr -d '\\n' > scratch/zx80base64.txt\n",
    "!openssl base64 -in scratch/zx81.jpg | tr -d '\\n' > scratch/zx81base64.txt\n",
    "!ls -la scratch/*base64.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d5900-3e28-4ee3-a8ae-2aff2a7368e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "file = 'scratch/zx81base64.txt'\n",
    "with open(file, 'r') as text:\n",
    "    textfile = text.read()\n",
    "import requests\n",
    "r = requests.post(url='http://127.0.0.1:7860/api/predict', json={\"data\":[\"data:image/png;base64,\"+textfile]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79a242-352f-4b23-b092-cc9ee0657122",
   "metadata": {},
   "source": [
    "### Call our model via CURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b9498-c691-4c4f-8948-70a58739080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm scratch/data.txt\n",
    "!touch scratch/data.txt\n",
    "!echo \"{\\\"data\\\":[\\\"data:image/png;base64,\" > scratch/data.txt\n",
    "!cat  scratch/zx80base64.txt >> scratch/data.txt\n",
    "!echo \"\\\"]}\" >> scratch/data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca04877-e681-4fe6-8d0e-d471153e7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -d \"@./scratch/data.txt\" -X POST http://127.0.0.1:7860/api/predict  -H \"Content-Type: application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71006ec1-73ac-41ff-84e5-1e97f23df2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
