{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282803b8-b94b-4976-bc01-4ad41d435ec4",
   "metadata": {},
   "source": [
    "<h1>ML for Dummies - leveraging ML models in your application in minutes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80dd378-d183-497a-b40d-643ea5d6ebd3",
   "metadata": {},
   "source": [
    "# Intro\n",
    "You don't need to be an AI/ML wizard to use ML models in your applications - in fact it is surprisingly easy.\n",
    "\n",
    "In this demo, we will create and deploy an app, that supports text sentiment analyis, image recognition and handwriting recognition, and is ready for you to wrap with your own business logic, using:\n",
    "- [Jupyter Labs](https://jupyter.org/) (A next-generation notebook/tutorial interface)\n",
    "- [Hugging Face](https://huggingface.co/docs/hub/index) (The Hugging Face Hub is a platform with over 350k models, 75k datasets, and 150k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together.)\n",
    "- [Gradio](https://www.gradio.app/) (Gradio is the fastest way to demo your machine learning model with a friendly web interface so that anyone can use it, anywhere!)\n",
    "\n",
    "<img src=\"./images/overview2.png\" alt=\"hackAithonWarmups\" class=\"custom-image\"  >\n",
    "\n",
    "# Prerequisites to follow this journey yourself:\n",
    "\n",
    "- install python: https://www.python.org  \n",
    "- install and launch Jupyter Labs: https://jupyter.org/install\n",
    "- create an account on HuggingFace: https://huggingface.co/docs/hub/index\n",
    "- install Git: https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\n",
    "- git clone https://github.com/kennylomax/aiwarmups.git\n",
    "- cd hackathonnotebooks\n",
    "- jupyter nbclassic hackAIthonWarmup1_0.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62eaa7-4a35-4091-93b6-9ed0c13fd287",
   "metadata": {},
   "source": [
    "# Background to Jupyter Notebooks...\n",
    "Jupyter pages are opened inside Jupyter Labs, and consist of a series of blocks/cells of code or markdown. \n",
    "- This paragraph is part of a markdown block. \n",
    "- The one below is a code block..  Code blocks can be RUN directly IN THE PAGE! :)\n",
    "- To **run a code cell**: Click inisde it, then Crtl-enter (or play button)\n",
    "- To **edit a code cell**: Double-click, then Shift-enter to leave edit mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbd364-2261-4c0a-b0e6-051ff743d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n",
    "!pwd\n",
    "print(\"HI there\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456bcd8-0c8a-43b4-a3f3-3f3e6dfaf882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some examples of what can be done in Jupyter Lab Code Blocks....\n",
    "# This is a code block, with code and comments:\n",
    "# Lines that start with a # are comments\n",
    "\n",
    "# This next line is a command that runs in python (because we are, by default, in a python Jupyter kernel):\n",
    "print (\"Hi there\")\n",
    "# Use a % to run OS commands, for example:\n",
    "!pwd\n",
    "!ls -la\n",
    "# To run this code block, click in it, and then click the \"play\" button at the top. You will then see the output printed below this block...\n",
    "# If you want to clear the page, select Kernel->\"Restart Kernel and Clear Outputs of All Cells...\" -> Restart\n",
    "# You can also store env variables (which we will see later), for example:\n",
    "import os\n",
    "os.environ['SOME_ENVIRONMENT_VARIABLE'] = \"Jupyter Labs are cool! It mixed docu with code on one page..\"\n",
    "!echo ${SOME_ENVIRONMENT_VARIABLE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f68519-e645-4498-8568-30b7e9cb04d9",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "# Journey\n",
    "\n",
    "## Explore Hugging Face\n",
    "\n",
    "[Hugging face](https://huggingface.co/docs/hub/index) is a portal for hosting and sharing ML Models and websites. We will be using some of the ML models that are available there, specifically:\n",
    "\n",
    "- [sentiment analysis](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest) \n",
    "- [image recognition](https://huggingface.co/facebook/convnext-xlarge-384-22k-1k)\n",
    "- [hand writing recognition](https://huggingface.co/microsoft/trocr-base-handwritten)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3304f85-74f1-43cc-912d-f561fc075640",
   "metadata": {},
   "source": [
    "## Create a Hugging Face token\n",
    "\n",
    "To access the REST endpoints of these models, we need a Hugging Face Token with WRITE permission:\n",
    "- Go to [https://huggingface.co/settings/tokens?new_token=true](https://huggingface.co/settings/tokens?new_token=true) and create a token with **WRITE** permission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024c70d-ab2d-43dc-bf5b-caccd3a31250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace xxx below with your Hugging Face Token, and then run this block to store the token as an environment variable (1) named HACKAITHONBEARERTOKEN\n",
    "\n",
    "import os\n",
    "os.environ['HACKAITHONBEARERTOKEN'] = \"Bearer xxx\"\n",
    "!echo ${HACKAITHONBEARERTOKEN}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103cf52d-8f78-41e7-a1c3-5abd03a2dc21",
   "metadata": {},
   "source": [
    "## Write code to call the Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f7003-eb81-4a26-8ea0-b8f5ed36587c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Open [sentiment analysis](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest) and follow this clickpath:<br>\n",
    "<img src=\"./images/hfcode.png\" style=\"width:300px;height:auto;\" >\n",
    "<br>Hugging Face will show you what code is necessary to call each model. In this case we will be calling the sentiment analysis model:<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73cf6f8-bfa1-486f-b842-13f3eae8dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your token, add a print statement,  and then run..\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "headers = {\"Authorization\": \"Bearer xxx\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"I feel super sad because Siggy just told me a joke!\",\n",
    "})\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bcccea-4e51-4a4a-a537-3829c9ecb7b7",
   "metadata": {},
   "source": [
    "We can take this code and adapt it so that:\n",
    "- we remove the hardcoded token and instead take if from the environment variable we stored earlier\n",
    "- we print out some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd249d0-f94d-4f73-acc4-ab94df4ddf02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this code block, and you should see (after ~10 seconds) that the ML model is called.\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# The API Endpoint of the twitter-roberta-base-sentiment ML Model, that we got from (2) above\n",
    "API_URL = \"https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "# Instead of hardcoding the token, we fetch it from the environment variable where we stored it earlier (1)\n",
    "bt = os.environ['HACKAITHONBEARERTOKEN']\n",
    "headers = {\"Authorization\": bt }\n",
    "\n",
    "# Call the ML Model's endpoint, passing in some text\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\t\n",
    "\n",
    "# Try out the model with 2 values:\n",
    "output = query({ \"inputs\": \"I feel amazing - totally over the moon!\"})\n",
    "print (output)\n",
    "\n",
    "output = query({ \"inputs\": \"I feel terrible, so sad:(\"})\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42855a-44de-476c-bd4d-1d6f79270e7a",
   "metadata": {},
   "source": [
    "## Write a small web app to wrap this logic with a friendly UI:\n",
    "\n",
    "Python websites declare their dependencies, by convention, in a requirements.txt file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f81bd-a4ab-400e-941d-d72dec1114bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~\n",
    "%mkdir hackaithon101\n",
    "%cd hackaithon101\n",
    "\n",
    "# Declare the dependencies\n",
    "requirementscode=\"\"\"\n",
    "gradio==3.48.0\n",
    "requests\n",
    "fastai\n",
    "\"\"\"\n",
    "f = open( 'requirements.txt', 'w' )\n",
    "f.write(requirementscode )\n",
    "f.close()\n",
    "\n",
    "!pwd\n",
    "!ls -la\n",
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5374d6ff-7d30-4182-a4c7-34e195fcccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3c4ed-300d-4f3c-bb14-b48a8ad5489d",
   "metadata": {},
   "source": [
    "We will use GRadio and the code we wrote earlier to create the UI (2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c2cce-adc2-4a3f-a168-c56763631062",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls -la\n",
    "servercode=\"\"\"\n",
    "import gradio as gr\n",
    "import requests\n",
    "import os\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "bt = os.environ['HACKAITHONBEARERTOKEN']\n",
    "headers = {\"Authorization\": bt }\n",
    "\n",
    "def query(data):\n",
    "    response = requests.post(API_URL, headers=headers, json=data)\n",
    "    return \"V2\"+str(response.json())\n",
    "\n",
    "def greet(howareyoufeeling):\n",
    "    output = query({\"inputs\":howareyoufeeling})\n",
    "    print (str(output))\n",
    "    return str(output)\n",
    "\n",
    "iface = gr.Interface(\n",
    "  fn=greet, inputs=[\"text\"], outputs=\"text\",  allow_flagging=\"never\")\n",
    "iface.launch()\n",
    "\"\"\"\n",
    "f = open( 'app.py', 'w' )\n",
    "f.write(servercode)\n",
    "f.close\n",
    "\n",
    "!pwd\n",
    "!ls -la\n",
    "!cat app.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f2ee55-a4ae-417c-836f-0988cc3b45f0",
   "metadata": {},
   "source": [
    "### Run your application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ffc40-dc19-40fa-9287-393bd633e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'app.py' \n",
    "# Wait a few seconds, and you should see the website's UI appear below.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6f26a-5adb-4ea1-bb85-6e74e8af5855",
   "metadata": {},
   "source": [
    "### Calling via API\n",
    "Explore the \"Use Via API\" option that should appear above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac420db-28c7-4b9f-8b13-4a4575d4a48d",
   "metadata": {},
   "source": [
    "Try opening your site via your browser at the url shown..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d6b6d-924e-4d21-bd34-3eedb8c2b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try calling it using the url described (adjust the port number)\n",
    "!curl 'http://127.0.0.1:7860/run/predict' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  --data-raw '{\"data\":[\"This is super fun!\"]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99faf457-73a4-4f94-bbfc-8d5bc0e9f380",
   "metadata": {},
   "source": [
    "## Deploy your app\n",
    "\n",
    "### Create a Hugging Face Space\n",
    "We will deploy this app to Hugging Face.  To do that we first need to create a new [Hugging Face Space](https://huggingface.co/spaces), which in this case we will call \"hackaithon101\"\n",
    "\n",
    "<img src=\"./images/hfs1.png\" style=\"width:300px;height:auto;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994cc704-531c-4cf2-be04-46c13c0cb9af",
   "metadata": {},
   "source": [
    "#### Place your token in a Hugging Face Secret\n",
    "\n",
    "We need to place our token in a hugging face secret so that it is secure.  Code running in hugging face will then be able to access that secret as a \"normal environment variable\".    \n",
    "In our example, the name should be HACKAITHONBEARERTOKEN and the value should be \"Bearer < HACKAITHONBEARERTOKEN >\" **without the quotes**: \n",
    "\n",
    "<img src=\"./images/hfsecret.png\" style=\"width:300px;height:auto;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc270bb9-26f9-4d9d-82bb-5cf5338526c8",
   "metadata": {},
   "source": [
    "#### Clone your Hugging Face Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e49746-bcb7-4737-a165-3fea988c46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir -p ~/hackaithon101/huggingfacerepo\n",
    "%cd ~/hackaithon101/huggingfacerepo\n",
    "!pwd\n",
    "!git clone https://huggingface.co/spaces/kenlomax/hackaithon101/\n",
    "!cd hackaithon101\n",
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f5a221-dcc4-4471-89fe-a1cece346965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the app.py and requirements.txt files into hackaithon101:\n",
    "%cd ~/hackaithon101/huggingfacerepo/hackaithon101\n",
    "!cp ~/hackaithon101/app.py .\n",
    "!cp ~/hackaithon101/requirements.txt .\n",
    "!pwd\n",
    "!ls -la\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f78da-0865-439e-acc5-5cc420241b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push the code to the hackaithon101 repo:\n",
    "# Personalize the next line : xxx should be your token\n",
    "!git remote set-url origin https://kenlomax:xxx@huggingface.co/spaces/kenlomax/hackaithon101\n",
    "# Push your changes to the hugging face repo:\n",
    "!git add .\n",
    "!git commit -m \"oooo\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ee748-f87d-4ab3-8139-cf24d343d824",
   "metadata": {},
   "source": [
    "\n",
    "### Try your app!\n",
    "\n",
    "You should soon see your website at https://huggingface.co/spaces/< yourname >/hackaithon101\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39e3ee-dbe0-4ee7-92f1-cf2d4ab024fb",
   "metadata": {},
   "source": [
    "### Extend the app to call the other 2 models too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2f224-b9b0-47b7-a11a-7568a6963080",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/hackaithon101/huggingfacerepo/hackaithon101\n",
    "!pwd\n",
    "!ls -latr\n",
    "\n",
    "servercode=\"\"\"\n",
    "import gradio as gr\n",
    "import requests\n",
    "import os\n",
    "\n",
    "API_URL1 = \"https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "API_URL2 = \"https://api-inference.huggingface.co/models/facebook/convnext-xlarge-384-22k-1k\"\n",
    "API_URL3 = \"https://api-inference.huggingface.co/models/microsoft/trocr-base-handwritten\"\n",
    "\n",
    "bt = os.environ['HACKAITHONBEARERTOKEN']\n",
    "headers = {\"Authorization\": bt }\n",
    "\n",
    "def query(mood, select_model, filepath):\n",
    "\n",
    "    print (select_model);\n",
    "    print (filepath);\n",
    "    \n",
    "    \n",
    "    if (select_model==\"Sentiment\"):\n",
    "    \tresponse = requests.post(API_URL1, headers=headers, json=mood)\n",
    "    elif (select_model==\"WhatIsThat\"):\n",
    "        data = open(filepath, 'rb' ).read()\n",
    "        response = requests.post(API_URL2, headers=headers, data=data)\n",
    "    else:\n",
    "        data = open(filepath, 'rb' ).read()\n",
    "        response = requests.post(API_URL3, headers=headers, data=data)\n",
    "    return str(response.json())\n",
    "\n",
    "def greet(mood,select_model,image):\n",
    "    output = query({\"inputs\":mood}, select_model, image)\n",
    "    print (str(output))\n",
    "    return str(output)\n",
    "\n",
    "iface = gr.Interface(\n",
    "  fn=greet, inputs=[\"text\", gr.Radio(choices=[\"Sentiment\", \"WhatIsThat\", \"HandWriting\"],value=\"Sentiment\"),gr.Image(type=\"filepath\")], outputs=\"text\")\n",
    "iface.launch()\n",
    "\"\"\"\n",
    "f = open( 'app.py', 'w' )\n",
    "f.write(servercode )\n",
    "f.close()\n",
    "!ls -latr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636b3af-ecae-4813-a4a2-41b6653d37e2",
   "metadata": {},
   "source": [
    "### Push the changes up to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad06a38-a307-45a5-a17b-d387748c950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"oooo\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f683c1-1298-43be-ab89-8bc20c9796e9",
   "metadata": {},
   "source": [
    "#### Try your app again\n",
    "\n",
    "You should soon see your website at https://huggingface.co/spaces/< yourname >/hackaithon101\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed73ab-6ef5-49c5-a900-514c86a273ef",
   "metadata": {},
   "source": [
    "### Delete your Hugging Face token \n",
    "If you are not going to use it anymore delete your tokens (and spaces) at [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
